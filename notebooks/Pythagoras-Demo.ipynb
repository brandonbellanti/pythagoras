{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythagoras\n",
    "\n",
    "Welcome to _Pythagoras_. The goal of this project is to identify and visualize relationships between musical works and composers based on pattern recognition. For more information, visit the [project website](http://web.simmons.edu/~bellanti/pythagoras) or the Github repo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* <a href=\"#Setting-up-the-environment\">Setting up the environment</a>\n",
    "* <a href=\"#Parsing-MusicXML-files\">Parsing MusicXML files</a>\n",
    "* <a href=\"#Building-a-dataframe-with-Pandas\">Building a dataframe with Pandas</a>\n",
    "* <a href=\"#Searching-for-patterns-with-regular-expressions\">Searching for patterns with regular expressions</a>\n",
    "* <a href=\"#Creating-a-pattern-database\">Creating a pattern database</a>\n",
    "    * <a href=\"#Create-tables\">Create tables</a>\n",
    "    * <a href=\"#Insert-values\">Insert values</a>\n",
    "    * <a href=\"#Queries\">Queries</a>\n",
    "* <a href=\"#Plotting-patterns-with-Matplotlib-and-MuseScore\">Plotting patterns with Matplotlib and MuseScore</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setting up the environment\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "Before running the code in this notebook, you will need the following libraries installed:\n",
    "* [Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html)\n",
    "* [NumPy](https://numpy.org/)\n",
    "* [Matplotlib](https://matplotlib.org/users/installing.html)\n",
    "* [lxml](https://lxml.de/installation.html)\n",
    "* [Regex](https://pypi.org/project/regex/)\n",
    "* [Music21](https://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parsing MusicXML files\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "The scores for this project have been converted from PDF files to MusicXML files using [Capella Scan](https://www.capella-software.com/us/index.cfm/products/capella-scan/info-capella-scan/). MusicXML is a standardized encoding format for digital scores; the MusicXML DTD can be found [here](https://www.musicxml.com/for-developers/musicxml-dtd/).\n",
    "\n",
    "The scores are then converted to CSV files: each <note/> element is represented by a row in the CSV file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"/Users/BrandonBel/Desktop/scores/\"\n",
    "xml_d = d + \"xml/\"\n",
    "csv_d = d + \"csv/\"\n",
    "\n",
    "for path in os.listdir(xml_d):\n",
    "    xml_filepath = xml_d + path\n",
    "    csv_filepath = xml_filepath.replace('xml','csv')\n",
    "\n",
    "    if path.replace('xml','csv') not in os.listdir(csv_d):\n",
    "        try:\n",
    "            xml_to_csv(xml_filepath,csv_filepath)\n",
    "            print(\"Conversion successful: %s --> %s\" % (path, path.replace('xml','csv')))\n",
    "        except:\n",
    "            print(\"Conversion failed: %s \" % path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(xml_filepath, csv_filepath):\n",
    "    tree = etree.parse(xml_filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(csv_filepath,'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(('part','measure','pitch','step','alter','octave','duration','type','dotted','rest','grace','cue'))\n",
    "        notes = []\n",
    "\n",
    "        for e in root.xpath('//note'):\n",
    "\n",
    "            part = e.xpath('../..//@id')[0]\n",
    "\n",
    "            measure = e.xpath('..//@number')[0]\n",
    "\n",
    "            dotted = True if 'dot' in [child.tag for child in e] else False\n",
    "\n",
    "            grace = True if 'grace' in [child.tag for child in e] else False\n",
    "\n",
    "            cue = True if 'cue' in [child.tag for child in e] else False\n",
    "\n",
    "            rest = True if 'rest' in [child.tag for child in e] else False\n",
    "\n",
    "            duration_list = e.xpath('.//duration/text()')\n",
    "            duration = duration_list[0] if len(duration_list)>0 else ''\n",
    "\n",
    "            typ_list = e.xpath('.//type/text()')\n",
    "            typ = typ_list[0] if len(typ_list)>0 else ''\n",
    "\n",
    "            step_list = e.xpath('.//step/text()')\n",
    "            step = step_list[0] if len(step_list)>0 else ''\n",
    "\n",
    "            alter_list = e.xpath('.//alter/text()')\n",
    "            alter = alter_list[0] if len(alter_list)>0 else ''\n",
    "            if alter == '0':\n",
    "                accidental = ''\n",
    "            elif alter == '-1':\n",
    "                accidental = 'b'\n",
    "            elif alter == '1':\n",
    "                accidental = '#'\n",
    "            elif alter == '-2':\n",
    "                accidental = 'bb'\n",
    "            elif alter == '2':\n",
    "                accidental = '##'\n",
    "            else:\n",
    "                accidental = ''\n",
    "\n",
    "            pitch = step + accidental\n",
    "\n",
    "            octave_list = e.xpath('.//octave/text()')\n",
    "            octave = octave_list[0] if len(step_list)>0 else ''\n",
    "\n",
    "            # notes.append((part,measure,pitch,step,alter,octave,duration,typ,dotted,rest,grace,cue))\n",
    "            writer.writerow((part,measure,pitch,step,alter,octave,duration,typ,dotted,rest,grace,cue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Building a dataframe with Pandas\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(notes,columns=['part','measure','pitch','step','alter','octave','duration','type','dotted','rest','grace','cue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in os.listdir(file_dir):\n",
    "    infile_path = file_dir + path\n",
    "    outfile_path = infile_path.replace('/csv/','/patterns/')\n",
    "    print(infile_path)\n",
    "    print(outfile_path)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '/Users/BrandonBel/Desktop/scores/csv/'\n",
    "completed_files = os.listdir('/Users/BrandonBel/Desktop/scores/patterns/')\n",
    "\n",
    "composer = \"Handel\"\n",
    "\n",
    "with open('logfile.csv','a') as logfile:\n",
    "    logwriter = csv.writer(logfile)\n",
    "#     logwriter.writerow(('file','status'))\n",
    "\n",
    "    for path in os.listdir(file_dir):\n",
    "        infile_path = file_dir + path\n",
    "        outfile_path = infile_path.replace('/csv/','/patterns/')\n",
    "        \n",
    "        if composer in path:\n",
    "            if path not in completed_files:\n",
    "                try:\n",
    "                    print(path)\n",
    "                    df = read_df(infile_path)\n",
    "                    string_dict = series_to_string_dict(df)\n",
    "                    pattern_list = find_patterns(string_dict, min_length=3, min_occur=3)\n",
    "\n",
    "                    with open(outfile_path,'w') as outfile:\n",
    "                        for pattern in pattern_list:\n",
    "                            outfile.write(pattern+'\\n')\n",
    "                    logwriter.writerow((path,'complete'))\n",
    "                except:\n",
    "                    continue\n",
    "                print()\n",
    "print('COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_dict = {'A0':'1','G##0':'1','Bbb0':'1','A#0':'2','Bb0':'2','Cbb1':'2','B0':'3','Cb1':'3','A##0':'3','C1':'4','B#0':'4','Dbb1':'4','C#1':'5','Db1':'5','B##1':'5','D1':'6','C##1':'6','Ebb1':'6','D#1':'7','Eb1':'7','Fbb1':'7','E1':'8','Fb1':'8','D##1':'8','1':'8','F1':'9','E#1':'9','Gbb1':'9','F#1':'10','Gb1':'10','E##1':'10','G1':'11','F##1':'11','Abb1':'11','G#1':'12','Ab1':'12','A1':'13','G##1':'13','Bbb1':'13','A#1':'14','Bb1':'14','Cbb1':'14','B1':'15','Cb1':'15','A##1':'15','C2':'16','B#1':'16','Dbb2':'16','C#2':'17','Db2':'17','B##2':'17','D2':'18','C##2':'18','Ebb2':'18','D#2':'19','Eb2':'19','Fbb2':'19','E2':'20','Fb2':'20','D##2':'20','2':'20','F2':'21','E#2':'21','Gbb2':'21','F#2':'22','Gb2':'22','E##2':'22','G2':'23','F##2':'23','Abb2':'23','G#2':'24','Ab2':'24','A2':'25','G##2':'25','Bbb2':'25','A#2':'26','Bb2':'26','Cbb2':'26','B2':'27','Cb2':'27','A##2':'27','C3':'28','B#2':'28','Dbb3':'28','C#3':'29','Db3':'29','B##3':'29','D3':'30','C##3':'30','Ebb3':'30','D#3':'31','Eb3':'31','Fbb3':'31','E3':'32','Fb3':'32','D##3':'32','3':'32','F3':'33','E#3':'33','Gbb3':'33','F#3':'34','Gb3':'34','E##3':'34','G3':'35','F##3':'35','Abb3':'35','G#3':'36','Ab3':'36','A3':'37','G##3':'37','Bbb3':'37','A#3':'38','Bb3':'38','Cbb3':'38','B3':'39','Cb3':'39','A##3':'39','C4':'40','B#3':'40','Dbb4':'40','C#4':'41','Db4':'41','B##4':'41','D4':'42','C##4':'42','Ebb4':'42','D#4':'43','Eb4':'43','Fbb4':'43','E4':'44','Fb4':'44','D##4':'44','4':'44','F4':'45','E#4':'45','Gbb4':'45','F#4':'46','Gb4':'46','E##4':'46','G4':'47','F##4':'47','Abb4':'47','G#4':'48','Ab4':'48','A4':'49','G##4':'49','Bbb4':'49','A#4':'50','Bb4':'50','Cbb4':'50','B4':'51','Cb4':'51','A##4':'51','C5':'52','B#4':'52','Dbb5':'52','C#5':'53','Db5':'53','B##5':'53','D5':'54','C##5':'54','Ebb5':'54','D#5':'55','Eb5':'55','Fbb5':'55','E5':'56','Fb5':'56','D##5':'56','5':'56','F5':'57','E#5':'57','Gbb5':'57','F#5':'58','Gb5':'58','E##5':'58','G5':'59','F##5':'59','Abb5':'59','G#5':'60','Ab5':'60','A5':'61','G##5':'61','Bbb5':'61','A#5':'62','Bb5':'62','Cbb5':'62','B5':'63','Cb5':'63','A##5':'63','C6':'64','B#5':'64','Dbb6':'64','C#6':'65','Db6':'65','B##6':'65','D6':'66','C##6':'66','Ebb6':'66','D#6':'67','Eb6':'67','Fbb6':'67','E6':'68','Fb6':'68','D##6':'68','6':'68','F6':'69','E#6':'69','Gbb6':'69','F#6':'70','Gb6':'70','E##6':'70','G6':'71','F##6':'71','Abb6':'71','G#6':'72','Ab6':'72','A6':'73','G##6':'73','Bbb6':'73','A#6':'74','Bb6':'74','Cbb6':'74','B6':'75','Cb6':'75','A##6':'75','C7':'76','B#6':'76','Dbb7':'76','C#7':'77','Db7':'77','B##7':'77','D7':'78','C##7':'78','Ebb7':'78','D#7':'79','Eb7':'79','Fbb7':'79','E7':'80','Fb7':'80','D##7':'80','7':'80','F7':'81','E#7':'81','Gbb7':'81','F#7':'82','Gb7':'82','E##7':'82','G7':'83','F##7':'83','Abb7':'83','G#7':'84','Ab7':'84','A7':'85','G##7':'85','Bbb7':'85','A#7':'86','Bb7':'86','Cbb8':'86','B7':'87','Cb8':'87','A##7':'87','C8':'88','B#7':'88','Dbb8':'88'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(infile_path):\n",
    "    \n",
    "    df = pd.read_csv(infile_path)\n",
    "    df['octave'] = df['octave'].loc[df['octave'].notna()].astype(int).astype(str)\n",
    "    df['keyboard_step'] = df['pitch'] + df['octave']\n",
    "    df['keyboard_step'].fillna('', inplace=True)\n",
    "    df['keyboard_step'] = df['keyboard_step'].apply(lambda x: int(pitch_dict[x]) if len(x)>0 else None)\n",
    "    df['interval'] = df['keyboard_step'].diff()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Searching for patterns with regular expressions\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "Using the string generated from the dataframe series, match any reoccuring patterns longer than a given length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_string_dict(df):\n",
    "        \n",
    "    string_dict = {}\n",
    "    parts = df['part'].unique()\n",
    "    \n",
    "    for part in parts:\n",
    "        part_df = df[df['part'] == part].fillna('')\n",
    "        steps = part_df['interval'].to_string(index=False, header=False)\n",
    "\n",
    "        # steps = re.sub(r'\\n|\\t| ','',steps)\n",
    "        steps = re.sub(r'\\n','.',steps)\n",
    "        steps = re.sub(r' ','',steps)\n",
    "    \n",
    "        string_dict[part] = steps\n",
    "        \n",
    "    return string_dict\n",
    "\n",
    "series_to_string_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_patterns(string_dict, min_length, min_occur):\n",
    "    pattern_list = []\n",
    "    for part in string_dict:\n",
    "        string = string_dict[part]\n",
    "        pat = r'((?<=\\.)[^.]+\\.(?:[^.]*\\.){%d,}[^.]+(?=\\.))(?:.*\\1){%d,}' % (min_length-2, min_occur-1)\n",
    "        patterns = re.findall(pat,string,overlapped=True)\n",
    "        for pattern in patterns:\n",
    "            if pattern not in pattern_list:\n",
    "                pattern_list.append(pattern)\n",
    "        print(\"Completed:\",part)\n",
    "\n",
    "    for pattern in pattern_list:\n",
    "        max_length = len(pattern.split('.'))\n",
    "        for length in range(max_length-1,min_length-1,-1):\n",
    "            pat = r'(^[^.]+\\.(?:[^.]*\\.){%d}[^.]+)' % (length-2)\n",
    "            alt_patterns = re.findall(pat,pattern,overlapped=True)\n",
    "            for alt_pattern in alt_patterns:\n",
    "                if alt_pattern not in pattern_list:\n",
    "                    pattern_list.append(alt_pattern)\n",
    "\n",
    "    return pattern_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_list = find_patterns(series_to_string_dict(df), min_length=2, min_occur=4)\n",
    "\n",
    "with open(outfile_path,'w') as outfile:\n",
    "    for pattern in pattern_list:\n",
    "        outfile.write(pattern+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_pattern_list(df):\n",
    "    string_dict = series_to_string_dict(df)\n",
    "    pattern_list = find_patterns(string_dict,min_length=4,min_occur=3)\n",
    "    return pattern_list\n",
    "\n",
    "patterns = df_to_pattern_list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Creating a pattern database\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "[SQLite3 documentation](https://docs.python.org/3.7/library/sqlite3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('pythagoras.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE IF NOT EXISTS work (\n",
    "    work_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    work_title text,\n",
    "    work_composer text\n",
    "    );''')\n",
    "conn.commit()\n",
    "\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS pattern (\n",
    "    pattern_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pattern_string text\n",
    "    );''')\n",
    "conn.commit()\n",
    "\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS work_pattern (\n",
    "    work_id INTEGER,\n",
    "    pattern_id INTEGER,\n",
    "    FOREIGN KEY (work_id) REFERENCES work(work_id),\n",
    "    FOREIGN KEY (pattern_id) REFERENCES pattern(pattern_id)\n",
    "    );''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show tables\n",
    "print(c.execute('''SELECT name from sqlite_master where type=\"table\";''').fetchall())\n",
    "\n",
    "# show columns\n",
    "print(c.execute('''PRAGMA table_info(pattern);''').fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.execute('''DROP TABLE IF EXISTS work;''')\n",
    "# c.execute('''DROP TABLE IF EXISTS pattern;''')\n",
    "# c.execute('''DROP TABLE IF EXISTS work_pattern;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"/Users/BrandonBel/Desktop/scores/csv/\")\n",
    "for file in files:\n",
    "    try:\n",
    "        m = re.match(r'(\\w*?)-(.*).csv',file)\n",
    "        composer = m.group(1)\n",
    "        title = m.group(2)\n",
    "#         print(\"\\nComposer:\", composer, \"\\nTitle: \", title)\n",
    "        \n",
    "        if c.execute('''SELECT COUNT(work_title) FROM work WHERE work_title=(?)''', (title,)).fetchone()[0] == 0:\n",
    "            c.execute('''INSERT INTO work(work_title, work_composer) VALUES (?,?)''',(title,composer))\n",
    "\n",
    "    except:\n",
    "        print(\"Cannot match: %s\" % file)\n",
    "        \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/Users/BrandonBel/Desktop/scores/patterns/\"\n",
    "pattern_files = os.listdir(dir_path)\n",
    "\n",
    "for path in pattern_files:\n",
    "    try:\n",
    "        m = re.match(r'(\\w*?)-(.*).csv',path)\n",
    "        composer = m.group(1)\n",
    "        title = m.group(2)\n",
    "        work_id = c.execute('''SELECT work_id FROM work WHERE work_title=(?)''', (title,)).fetchone()[0]\n",
    "        print(\"\\nComposer:\", composer, \"\\nTitle:\", title,\"\\nDB ID:\",work_id)\n",
    "\n",
    "        with open(dir_path+path,'r') as pattern_file:\n",
    "            for line in pattern_file:\n",
    "                pattern_string = line.rstrip()\n",
    "    #             if c.execute('''SELECT COUNT(pattern_id) FROM pattern WHERE pattern_string=(?);''', (pattern_string,)).fetchone()[0] == 0:\n",
    "    #                 c.execute('''INSERT INTO pattern(pattern_string) VALUES (?);''',(pattern_string,))\n",
    "                try:\n",
    "                    pattern_id = c.execute('''SELECT pattern_id FROM pattern WHERE pattern_string=(?);''', (pattern_string,)).fetchone()[0]\n",
    "                except:\n",
    "                    c.execute('''INSERT INTO pattern(pattern_string) VALUES (?);''',(pattern_string,))\n",
    "                    pattern_id = c.execute('''SELECT pattern_id FROM pattern WHERE pattern_string=(?);''', (pattern_string,)).fetchone()[0]\n",
    "\n",
    "\n",
    "    #                 print(\"\\t\",pattern_id, pattern_string)\n",
    "    #                 if c.execute('''SELECT COUNT(work_id) FROM work_pattern WHERE work_id=(?) AND pattern_id=(?);''', (work_id,pattern_id)).fetchone()[0] == 0:\n",
    "    #                     c.execute('''INSERT INTO work_pattern(work_id, pattern_id) VALUES (?,?);''',(work_id,pattern_id))\n",
    "                c.execute('''INSERT INTO work_pattern(work_id, pattern_id) VALUES (?,?);''',(work_id,pattern_id))\n",
    "            print('Status: Complete')\n",
    "            conn.commit()\n",
    "    except:\n",
    "        print('\\n',\"*\"*80)\n",
    "        print(\"Can't find title:\",path)\n",
    "        print(\"*\"*80,'\\n')\n",
    "\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db(infile_path, database_name):\n",
    "    conn = sqlite3.connect(database_name)\n",
    "    c = conn.cursor()\n",
    "    m = re.match(r'(\\w*?)-(.*).csv',path)\n",
    "    composer = m.group(1)\n",
    "    title = m.group(2)\n",
    "    try:\n",
    "        work_id = c.execute('''SELECT work_id FROM work WHERE work_title=(?)''', (title,)).fetchone()[0]\n",
    "    except:\n",
    "        c.execute('''INSERT INTO work(work_title, work_composer) VALUES (?,?)''',(title,composer))\n",
    "        work_id = c.execute('''SELECT work_id FROM work WHERE work_title=(?)''', (title,)).fetchone()[0]\n",
    "    with open(infile_path,'r') as pattern_file:\n",
    "        for line in pattern_file:\n",
    "            pattern_string = line.rstrip()\n",
    "            try:\n",
    "                pattern_id = c.execute('''SELECT pattern_id FROM pattern WHERE pattern_string=(?);''', (pattern_string,)).fetchone()[0]\n",
    "            except:\n",
    "                c.execute('''INSERT INTO pattern(pattern_string) VALUES (?);''',(pattern_string,))\n",
    "                pattern_id = c.execute('''SELECT pattern_id FROM pattern WHERE pattern_string=(?);''', (pattern_string,)).fetchone()[0]\n",
    "            c.execute('''INSERT INTO work_pattern(work_id, pattern_id) VALUES (?,?);''',(work_id,pattern_id))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 23 files in the directory\n",
    "\n",
    "for row in c.execute('''SELECT COUNT(DISTINCT(work_id)) FROM work;'''):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max number of patterns used in one piece\n",
    "\n",
    "print(\"Composer, Title, Number of patterns\")\n",
    "for row in c.execute('''\n",
    "SELECT composer, title, MAX(pattern_count)\n",
    "FROM (\n",
    "SELECT work_composer AS composer,\n",
    "work_title AS title,\n",
    "COUNT(work_pattern.pattern_id) AS pattern_count\n",
    "FROM work_pattern\n",
    "JOIN work on work.work_id = work_pattern.work_id\n",
    "GROUP BY work_title)\n",
    ";'''):\n",
    "    print(f\"{row[0]}, {row[1]}, {row[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in c.execute('''\n",
    "    SELECT work_title, work_composer, COUNT(pattern.pattern_id)\n",
    "    FROM (work JOIN work_pattern ON work.work_id=work_pattern.work_id)\n",
    "    JOIN pattern ON work_pattern.pattern_id=pattern.pattern_id\n",
    "    GROUP BY work.work_id\n",
    ";'''):\n",
    "    print(\"Title: %s\\nComposer: %s\\nPatterns: %d\\n\" % (row[0],row[1],row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_length = 10\n",
    "number_of_works = 5\n",
    "\n",
    "for row in c.execute('''\n",
    "    SELECT pattern_string, GROUP_CONCAT(work.work_title, ', ')\n",
    "    FROM (work JOIN work_pattern ON work.work_id=work_pattern.work_id)\n",
    "    JOIN pattern ON work_pattern.pattern_id=pattern.pattern_id\n",
    "    WHERE LENGTH(pattern_string)>=(?)\n",
    "    GROUP BY pattern.pattern_string\n",
    "    HAVING COUNT(pattern_string)>=(?)\n",
    ";''', (pattern_length,number_of_works)):\n",
    "    \n",
    "    print(\"Pattern: %s\\nWorks: %s\\n\" % (row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(sql):\n",
    "    return c.execute(sql)\n",
    "    \n",
    "sql = '''\n",
    "SELECT pattern_string, GROUP_CONCAT(work.work_title, ', ')\n",
    "FROM (work JOIN work_pattern ON work.work_id=work_pattern.work_id)\n",
    "JOIN pattern ON work_pattern.pattern_id=pattern.pattern_id\n",
    "WHERE LENGTH(pattern_string)>=(10)\n",
    "GROUP BY pattern.pattern_string\n",
    "HAVING COUNT(work_pattern.work_id)>=(5)\n",
    ";'''\n",
    "results = query_db(sql)\n",
    "for row in results:\n",
    "    print(f\"Pattern:\\t{row[0]}\\nWorks:\\t{row[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def query_db(database_name, sql):\n",
    "    conn = sqlite3.connect(database_name)\n",
    "    c = conn.cursor()\n",
    "    return c.execute(sql)\n",
    "    \n",
    "sql = '''\n",
    "SELECT pattern_string, GROUP_CONCAT(work.work_title, ', '), GROUP_CONCAT(DISTINCT work_composer),COUNT(work.work_title)\n",
    "FROM (work JOIN work_pattern ON work.work_id=work_pattern.work_id)\n",
    "JOIN pattern ON work_pattern.pattern_id=pattern.pattern_id\n",
    "WHERE LENGTH(pattern_string)>=(20)\n",
    "GROUP BY pattern.pattern_string\n",
    "HAVING COUNT(work_pattern.work_id)>=(5)\n",
    ";'''\n",
    "results = query_db('pythagoras.db', sql)\n",
    "for row in results:\n",
    "    print(f\"Pattern:\\t{row[0]}\\nComposers:\\t{row[2]}\\nAppears in:\\t{row[3]} works\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT pattern_string, GROUP_CONCAT(DISTINCT work_composer), COUNT(work_pattern.work_id)\n",
    "FROM (work JOIN work_pattern ON work.work_id=work_pattern.work_id)\n",
    "JOIN pattern ON work_pattern.pattern_id=pattern.pattern_id\n",
    "WHERE LENGTH(pattern_string)>=(20)\n",
    "GROUP BY pattern.pattern_string\n",
    "HAVING COUNT(work_pattern.work_id)>=(5)\n",
    ";'''\n",
    "\n",
    "results = query_db('pythagoras.db', sql)\n",
    "for count,row in enumerate(results,1):\n",
    "#     print(f\"Row:\\t{count}\\nTitle:\\t{row[0]}\\nComp:\\t{row[1]}\")\n",
    "    print(count,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in c.execute('''SELECT COUNT(work_title) FROM work WHERE NOT work_composer = \"Beethoven\";'''):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in c.execute('''SELECT * FROM work WHERE work_title LIKE \"%opus%\";'''):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Plotting patterns with Matplotlib and MuseScore\n",
    "\n",
    "<a href=\"#Table-of-Contents\">Return to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_dict_flats = {-19:\"F\",-18:\"Gb\",-17:\"G\",-16:\"Ab\",-15:\"A\",-14:\"Bb\",-13:\"B\",-12:\"C\",-11:\"Db\",-10:\"D\",-9:\"Eb\",-8:\"E\",-7:\"F\",-6:\"Gb\",-5:\"G\",-4:\"Ab\",-3:\"A\",-2:\"Bb\",-1:\"B\",0:\"C\",1:\"Db\",2:\"D\",3:\"Eb\",4:\"E\",5:\"F\",6:\"Gb\",7:\"G\",8:\"Ab\",9:\"A\",10:\"Bb\",11:\"B\",12:\"C\",13:\"Db\",14:\"D\",15:\"Eb\",16:\"E\",17:\"F\",18:\"Gb\",19:\"G\" }\n",
    "note_dict_sharps = {-19:\"F\",-18:\"F#\",-17:\"G\",-16:\"G#\",-15:\"A\",-14:\"A#\",-13:\"B\",-12:\"C\",-11:\"C#\",-10:\"D\",-9:\"D#\",-8:\"E\",-7:\"F\",-6:\"F#\",-5:\"G\",-4:\"G#\",-3:\"A\",-2:\"A#\",-1:\"B\",0:\"C\",1:\"C#\",2:\"D\",3:\"D#\",4:\"E\",5:\"F\",6:\"F#\",7:\"G\",8:\"G#\",9:\"A\",10:\"A#\",11:\"B\",12:\"C\",13:\"C#\",14:\"D\",15:\"D#\",16:\"E\",17:\"F\",18:\"F#\",19:\"G\"}\n",
    "note_dict_music21_sharps = {-19:\"F\",-18:\"F#\",-17:\"G\",-16:\"G#\",-15:\"A\",-14:\"A#\",-13:\"B\",-12:\"c\",-11:\"c#\",-10:\"d\",-9:\"d#\",-8:\"e\",-7:\"f\",-6:\"f#\",-5:\"g\",-4:\"g#\",-3:\"a\",-2:\"a#\",-1:\"b\",0:\"c'\",1:\"c#'\",2:\"d'\",3:\"d#'\",4:\"e'\",5:\"f'\",6:\"f'#\",7:\"g'\",8:\"g'#\",9:\"a'\",10:\"a'#\",11:\"b'\"}\n",
    "note_dict_music21_flats = {-19:\"F\",-18:\"G-\",-17:\"G\",-16:\"A-\",-15:\"A\",-14:\"B-\",-13:\"B\",-12:\"c\",-11:\"d-\",-10:\"d\",-9:\"e-\",-8:\"e\",-7:\"f\",-6:\"g-\",-5:\"g\",-4:\"a-\",-3:\"a\",-2:\"b-\",-1:\"b\",0:\"c'\",1:\"d'-\",2:\"d'\",3:\"e'-\",4:\"e'\",5:\"f'\",6:\"g'-\",7:\"g'\",8:\"a'-\",9:\"a'\",10:\"b'-\",11:\"b'\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pattern(interval_string):\n",
    "\n",
    "    str_intervals = interval_string.split('.') # split the string at the dots \n",
    "    int_intervals = list(map(int, str_intervals)) # convert str to int\n",
    "\n",
    "    steps = []\n",
    "    step = 0 # initial step\n",
    "    steps.append(step) # add initial step to list\n",
    "    \n",
    "    for interval in int_intervals:\n",
    "        step += interval \n",
    "        steps.append(step)\n",
    "\n",
    "    notes = [note_dict_flats[step] for step in steps]\n",
    "\n",
    "    print(f\"Interval pattern:\\t{' '.join([str(x) for x in str_intervals])}\")\n",
    "    print(f\"Steps pattern:\\t\\t{' '.join([str(x) for x in steps])}\")\n",
    "    print(f\"Pitches pattern:\\t{' '.join([str(x) for x in notes])}\")\n",
    "    \n",
    "    # musescore visualization\n",
    "    try:\n",
    "        mus21_notes = [note_dict_music21_flats[step] for step in steps]\n",
    "        tinyNotation = \"tinyNotation: \"+ ' '.join(mus21_notes)\n",
    "        fakePiece = converter.parse(tinyNotation)\n",
    "        fakePiece.show()\n",
    "    except:\n",
    "        print(\"Unable to plot pattern to musical staff\")\n",
    "    \n",
    "    # matplotlib visualization\n",
    "    plt.plot(steps, 's', markersize=20)\n",
    "    for count, step in enumerate(steps):\n",
    "        plt.text(count-.15 ,step-.1, notes[count], color='w', weight='bold')\n",
    "    plt.show()\n",
    "        \n",
    "    print('*'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    pattern_string,\n",
    "    COUNT(DISTINCT(work_pattern.work_id)) as work_count,\n",
    "    COUNT(DISTINCT(work_composer)) as composer_count,\n",
    "    GROUP_CONCAT(DISTINCT(work_composer))\n",
    "FROM pattern\n",
    "JOIN work_pattern on pattern.pattern_id=work_pattern.pattern_id\n",
    "JOIN work on work.work_id=work_pattern.work_id\n",
    "GROUP BY pattern_string\n",
    "HAVING work_count>5\n",
    "AND LENGTH(pattern_string)>10\n",
    "ORDER BY work_count DESC\n",
    "LIMIT 5;'''\n",
    "\n",
    "results = query_db(sql)\n",
    "for row in results:\n",
    "    interval_string = row[0]\n",
    "    print(f\"Apears in:\\t\\t{row[1]} works from {row[2]} composers ({row[3]})\")\n",
    "    plot_pattern(interval_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
